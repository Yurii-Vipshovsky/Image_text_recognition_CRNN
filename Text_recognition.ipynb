{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from PIL import Image as pilImg\n",
    "import os \n",
    "import cv2\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Підготовка Даних із завантаженого датасета із Англійскими словами\n",
    "Source: https://www.robots.ox.ac.uk/~vgg/data/text/#sec-synth"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Із file_path (шлях до txt файлу із описами картинок) отримує картинки у кількості number\n",
    "Повертає тільки картинки з текстом розміром від 4 до 12 елементів\n",
    "\n",
    "Takes the file path of images annotation txt file with the number of images names to be extracted\n",
    "and returns the list of file names having label length <=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_image_names(file_path, number):\n",
    "    with open(file_path) as file:\n",
    "        files = file.readlines()\n",
    "        file.close()\n",
    "        count = 0\n",
    "        img_names = []\n",
    "        for f in files:\n",
    "            \"\"\"\n",
    "            Extract from 'SynthImageDataset./2425/1/115_Lube_45484.jpg 45484' only image lable - Lube\n",
    "            \"\"\"\n",
    "            label = f.split('_')[1]\n",
    "            if len(label) >= 4 and len(label) <= 12:\n",
    "                img_names.append(f)\n",
    "                count += 1\n",
    "            if count == number:\n",
    "                break\n",
    "        images_names=['SynthImageDataset' + x.strip() for x in img_names]\n",
    "        #Clears date deleting number from end of name\n",
    "        res_files = []\n",
    "        for file in images_names:\n",
    "            main_folder, img_loc, extension = file.split('.')\n",
    "            extension = extension.split(' ')[0]\n",
    "            img_file = main_folder + img_loc + '.' + extension\n",
    "            res_files.append(img_file)\n",
    "        return res_files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У змінну для навчання записуєм 200000 шляхів до картинок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SynthImageDataset/2425/1/115_Lube_45484.jpg',\n",
       " 'SynthImageDataset/2425/1/114_Spencerian_73323.jpg',\n",
       " 'SynthImageDataset/2425/1/112_CARPENTER_11682.jpg',\n",
       " 'SynthImageDataset/2425/1/110_savannas_67969.jpg',\n",
       " 'SynthImageDataset/2425/1/109_unfix_82473.jpg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images = Extract_image_names('SynthImageDataset/annotation_train.txt',200000)\n",
    "train_images[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SynthImageDataset/2425/1/115_Lube_45484.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SynthImageDataset/2425/1/114_Spencerian_73323.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SynthImageDataset/2425/1/112_CARPENTER_11682.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SynthImageDataset/2425/1/110_savannas_67969.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SynthImageDataset/2425/1/109_unfix_82473.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           ImageName\n",
       "0        SynthImageDataset/2425/1/115_Lube_45484.jpg\n",
       "1  SynthImageDataset/2425/1/114_Spencerian_73323.jpg\n",
       "2   SynthImageDataset/2425/1/112_CARPENTER_11682.jpg\n",
       "3    SynthImageDataset/2425/1/110_savannas_67969.jpg\n",
       "4       SynthImageDataset/2425/1/109_unfix_82473.jpg"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pandas.DataFrame({'ImageName':train_images})\n",
    "train_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Із файлів отримуємо назви картинок, які відповідають тексту на картинках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_values(files):\n",
    "    \"\"\"\n",
    "    Given the file names of images, extracts the Values and returns a list of Labels in Upper Case\n",
    "    \"\"\"\n",
    "    txt_labels = []\n",
    "    for file in files:\n",
    "        values = file.split('_')[1]\n",
    "        values = values.upper()\n",
    "        txt_labels.append(values)\n",
    "    return txt_labels   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SynthImageDataset/2425/1/115_Lube_45484.jpg</td>\n",
       "      <td>LUBE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SynthImageDataset/2425/1/114_Spencerian_73323.jpg</td>\n",
       "      <td>SPENCERIAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SynthImageDataset/2425/1/112_CARPENTER_11682.jpg</td>\n",
       "      <td>CARPENTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SynthImageDataset/2425/1/110_savannas_67969.jpg</td>\n",
       "      <td>SAVANNAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SynthImageDataset/2425/1/109_unfix_82473.jpg</td>\n",
       "      <td>UNFIX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           ImageName      Labels\n",
       "0        SynthImageDataset/2425/1/115_Lube_45484.jpg        LUBE\n",
       "1  SynthImageDataset/2425/1/114_Spencerian_73323.jpg  SPENCERIAN\n",
       "2   SynthImageDataset/2425/1/112_CARPENTER_11682.jpg   CARPENTER\n",
       "3    SynthImageDataset/2425/1/110_savannas_67969.jpg    SAVANNAS\n",
       "4       SynthImageDataset/2425/1/109_unfix_82473.jpg       UNFIX"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_values = extract_values(train_images)\n",
    "#Add to csv Label for Images\n",
    "train_data['Labels'] = train_values\n",
    "train_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Створюємо csv файли із шляхами до картинок і текстом на них\n",
    "\n",
    "Create Train Data csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('Train_data.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SynthImageDataset/2697/6/466_MONIKER_49537.jpg</td>\n",
       "      <td>MONIKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SynthImageDataset/2697/6/464_FIRESTORM_29099.jpg</td>\n",
       "      <td>FIRESTORM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SynthImageDataset/2697/6/462_Repurchases_64997...</td>\n",
       "      <td>REPURCHASES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SynthImageDataset/2697/6/461_PIGTAIL_57575.jpg</td>\n",
       "      <td>PIGTAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SynthImageDataset/2697/6/460_landladies_43270.jpg</td>\n",
       "      <td>LANDLADIES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           ImageName       Labels\n",
       "0     SynthImageDataset/2697/6/466_MONIKER_49537.jpg      MONIKER\n",
       "1   SynthImageDataset/2697/6/464_FIRESTORM_29099.jpg    FIRESTORM\n",
       "2  SynthImageDataset/2697/6/462_Repurchases_64997...  REPURCHASES\n",
       "3     SynthImageDataset/2697/6/461_PIGTAIL_57575.jpg      PIGTAIL\n",
       "4  SynthImageDataset/2697/6/460_landladies_43270.jpg   LANDLADIES"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_images = Extract_image_names('SynthImageDataset/annotation_val.txt',12000)\n",
    "val_data = pandas.DataFrame({'ImageName':validation_images})\n",
    "Val_values = extract_values(validation_images)\n",
    "val_data['Labels'] = Val_values\n",
    "val_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.to_csv('Validation_data.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SynthImageDataset/3000/7/182_slinking_71711.jpg</td>\n",
       "      <td>SLINKING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SynthImageDataset/3000/7/181_REMODELERS_64541.jpg</td>\n",
       "      <td>REMODELERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SynthImageDataset/3000/7/180_Chronographs_1353...</td>\n",
       "      <td>CHRONOGRAPHS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SynthImageDataset/3000/7/179_Impeaching_38222.jpg</td>\n",
       "      <td>IMPEACHING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SynthImageDataset/3000/7/177_Loots_45256.jpg</td>\n",
       "      <td>LOOTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           ImageName        Labels\n",
       "0    SynthImageDataset/3000/7/182_slinking_71711.jpg      SLINKING\n",
       "1  SynthImageDataset/3000/7/181_REMODELERS_64541.jpg    REMODELERS\n",
       "2  SynthImageDataset/3000/7/180_Chronographs_1353...  CHRONOGRAPHS\n",
       "3  SynthImageDataset/3000/7/179_Impeaching_38222.jpg    IMPEACHING\n",
       "4       SynthImageDataset/3000/7/177_Loots_45256.jpg         LOOTS"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images = Extract_image_names('SynthImageDataset/annotation_test.txt',15000)\n",
    "test_data = pandas.DataFrame({'ImageName':test_images})\n",
    "test_values = extract_values(test_images)\n",
    "test_data['Labels'] = test_values\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv('Test_data.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перетворення картинок у відтінки сірого\n",
    "\n",
    "Зчитує картинку із файла, перетворює у відтінки сірого і записує у нову папку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_store_single_channel(destination_folder, files):\n",
    "    \"\"\"\n",
    "    Takes files, distination folder path and \n",
    "    converts the image to single channel gray scale,\n",
    "    stores the image in the destination folder and returns image destination list\n",
    "    \"\"\"\n",
    "    timer_start = datetime.now()\n",
    "    destination_list = []\n",
    "    count = 1\n",
    "    for file in files:\n",
    "        #Removing the extra folder structures\n",
    "        Name = file.split('/')[3]\n",
    "        img = Name.split('_')[1]\n",
    "        destination = destination_folder + str(count) + '_' + img + '.jpg'\n",
    "        cv_img = cv2.imread(file)\n",
    "        #So extracting image from any 1 channel gives a single channel Grayscale image\n",
    "        cv_img_sc = cv_img[:, :, 1]\n",
    "        cv2.imwrite(destination, cv_img_sc)\n",
    "        destination_list.append(destination)\n",
    "        count += 1\n",
    "        if count % 10000 == 0:\n",
    "            print(\"Processed Images: \", count)\n",
    "    print('Time Taken for Processing: ', datetime.now() - timer_start)\n",
    "    return destination_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обробка картинок\n",
    "\n",
    "Processing Validation Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оброблені картинки зберіагаються до папки Val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Images:  10000\n",
      "Time Taken for Processing:  0:00:27.882640\n"
     ]
    }
   ],
   "source": [
    "val_data = pandas.read_csv('Validation_data.csv')\n",
    "val_data.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "val_files = val_data['ImageName'].values\n",
    "#os.mkdir('Val_data')\n",
    "val_dest = img_store_single_channel('Val_data/', val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Val_data/1_MONIKER.jpg</td>\n",
       "      <td>MONIKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Val_data/2_FIRESTORM.jpg</td>\n",
       "      <td>FIRESTORM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Val_data/3_Repurchases.jpg</td>\n",
       "      <td>REPURCHASES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Val_data/4_PIGTAIL.jpg</td>\n",
       "      <td>PIGTAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Val_data/5_landladies.jpg</td>\n",
       "      <td>LANDLADIES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ImageName       Labels\n",
       "0      Val_data/1_MONIKER.jpg      MONIKER\n",
       "1    Val_data/2_FIRESTORM.jpg    FIRESTORM\n",
       "2  Val_data/3_Repurchases.jpg  REPURCHASES\n",
       "3      Val_data/4_PIGTAIL.jpg      PIGTAIL\n",
       "4   Val_data/5_landladies.jpg   LANDLADIES"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Updating Validation Dataframe with new destination file paths\n",
    "val_data['ImageName'] = val_dest\n",
    "val_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Створення фінального валідаційного датафрему з обробленими картинками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the updated Validation Dataframe\n",
    "val_data.to_csv('Validation_Final.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Images:  10000\n",
      "Time Taken for Processing:  0:00:51.791081\n"
     ]
    }
   ],
   "source": [
    "test_data = pandas.read_csv('Test_data.csv')\n",
    "test_data.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "test_files = test_data['ImageName'].values\n",
    "#os.mkdir('Test_data')\n",
    "test_dest = img_store_single_channel('Test_data/', test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test_data/1_slinking.jpg</td>\n",
       "      <td>SLINKING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test_data/2_REMODELERS.jpg</td>\n",
       "      <td>REMODELERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test_data/3_Chronographs.jpg</td>\n",
       "      <td>CHRONOGRAPHS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Test_data/4_Impeaching.jpg</td>\n",
       "      <td>IMPEACHING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Test_data/5_Loots.jpg</td>\n",
       "      <td>LOOTS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ImageName        Labels\n",
       "0      Test_data/1_slinking.jpg      SLINKING\n",
       "1    Test_data/2_REMODELERS.jpg    REMODELERS\n",
       "2  Test_data/3_Chronographs.jpg  CHRONOGRAPHS\n",
       "3    Test_data/4_Impeaching.jpg    IMPEACHING\n",
       "4         Test_data/5_Loots.jpg         LOOTS"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Updating Test Dataframe with new destination file paths\n",
    "test_data['ImageName'] = test_dest\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the updated Test Dataframe\n",
    "test_data.to_csv('Test_Final.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Images:  10000\n",
      "Processed Images:  20000\n",
      "Processed Images:  30000\n",
      "Processed Images:  40000\n",
      "Processed Images:  50000\n",
      "Processed Images:  60000\n",
      "Processed Images:  70000\n",
      "Processed Images:  80000\n",
      "Processed Images:  90000\n",
      "Processed Images:  100000\n",
      "Processed Images:  110000\n",
      "Processed Images:  120000\n",
      "Processed Images:  130000\n",
      "Processed Images:  140000\n",
      "Processed Images:  150000\n",
      "Processed Images:  160000\n",
      "Processed Images:  170000\n",
      "Processed Images:  180000\n",
      "Processed Images:  190000\n",
      "Processed Images:  200000\n",
      "Time Taken for Processing:  0:09:07.144117\n"
     ]
    }
   ],
   "source": [
    "train_data = pandas.read_csv('Train_data.csv')\n",
    "train_data.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "train_files = train_data['ImageName'].values\n",
    "#os.mkdir('Train_data')\n",
    "train_dest = img_store_single_channel('Train_data/', train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageName</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train_data/1_Lube.jpg</td>\n",
       "      <td>LUBE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train_data/2_Spencerian.jpg</td>\n",
       "      <td>SPENCERIAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train_data/3_CARPENTER.jpg</td>\n",
       "      <td>CARPENTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train_data/4_savannas.jpg</td>\n",
       "      <td>SAVANNAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train_data/5_unfix.jpg</td>\n",
       "      <td>UNFIX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ImageName      Labels\n",
       "0        Train_data/1_Lube.jpg        LUBE\n",
       "1  Train_data/2_Spencerian.jpg  SPENCERIAN\n",
       "2   Train_data/3_CARPENTER.jpg   CARPENTER\n",
       "3    Train_data/4_savannas.jpg    SAVANNAS\n",
       "4       Train_data/5_unfix.jpg       UNFIX"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Updating Train Dataframe with new destination file paths\n",
    "train_data['ImageName'] = train_dest\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the updated Train Dataframe\n",
    "train_data.to_csv('Train_Final.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналіз розміру (розширення) катинок\n",
    "\n",
    "Image Size Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зчитує із масиву filenames шляхи до картинок, відкриває кожну і записує у storage_file назву картинки, її висоту та ширину"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Write_Image_Sizes(filenames, storage_file):\n",
    "    \"\"\"\n",
    "    Takes the File names, writes the width and height of images in csv along with file names\n",
    "    \"\"\"\n",
    "    store_file = open(storage_file, 'w+')\n",
    "    store_file.write(\"ImageName,Height,Width\")\n",
    "    store_file.write(\"\\n\")\n",
    "    counter = 0\n",
    "    for file in filenames:\n",
    "        cv_img = cv2.imread(file)\n",
    "        #img.shape gives [img_height, img_width, img_channel] take 0 and 1\n",
    "        store_file.write(str(file) + \",\" + str(cv_img.shape[0]) + \",\" + str(cv_img.shape[1]))\n",
    "        store_file.write(\"\\n\")\n",
    "        counter += 1\n",
    "        if counter % 10000 == 0:\n",
    "            print(\"Processed Images: \", counter)\n",
    "    store_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Images:  10000\n",
      "Processed Images:  20000\n",
      "Processed Images:  30000\n",
      "Processed Images:  40000\n",
      "Processed Images:  50000\n",
      "Processed Images:  60000\n",
      "Processed Images:  70000\n",
      "Processed Images:  80000\n",
      "Processed Images:  90000\n",
      "Processed Images:  100000\n",
      "Processed Images:  110000\n",
      "Processed Images:  120000\n",
      "Processed Images:  130000\n",
      "Processed Images:  140000\n",
      "Processed Images:  150000\n",
      "Processed Images:  160000\n",
      "Processed Images:  170000\n",
      "Processed Images:  180000\n",
      "Processed Images:  190000\n",
      "Processed Images:  200000\n"
     ]
    }
   ],
   "source": [
    "train_data = pandas.read_csv('Train_data.csv')\n",
    "Write_Image_Sizes(list(train_data['ImageName'].values), 'Train_image_sizes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31.038550</td>\n",
       "      <td>115.668015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.333698</td>\n",
       "      <td>39.696249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>88.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>109.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>136.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>608.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Height          Width\n",
       "count  200000.000000  200000.000000\n",
       "mean       31.038550     115.668015\n",
       "std         0.333698      39.696249\n",
       "min         9.000000       1.000000\n",
       "25%        31.000000      88.000000\n",
       "50%        31.000000     109.000000\n",
       "75%        31.000000     136.000000\n",
       "max        32.000000     608.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img_size = pandas.read_csv('Train_image_sizes.csv')\n",
    "train_img_size.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images Height 90 percentile : 31.0\n",
      "Train Images Height 99 percentile : 32.0\n",
      "Train Images Width 90 percentile : 167.0\n",
      "Train Images Width 99 percentile : 240.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Images Height 90 percentile :\", np.percentile(train_img_size['Height'].values, 90))\n",
    "print(\"Train Images Height 99 percentile :\", np.percentile(train_img_size['Height'].values, 99))\n",
    "print(\"Train Images Width 90 percentile :\", np.percentile(train_img_size['Width'].values, 90))\n",
    "print(\"Train Images Width 99 percentile :\", np.percentile(train_img_size['Width'].values, 99))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Це показує, що 90 процентиль висоти картинок 31 піксель, 99 процентиль 32 пікселя\n",
    "\n",
    "А по ширині 90 процентиль 167 пікселів, 99 процентиль 240 пікселів"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Графік CDF (акумулююча функція) для висот картинок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdf_image_heights(label_len):\n",
    "    \"\"\"\n",
    "    Takes a list of image heights as input and Plots CDF of image heights\n",
    "    \"\"\"\n",
    "    plt.figure(figsize = (10,6))\n",
    "    count_labels = np.array(label_len)\n",
    "    counts, bin_edges = np.histogram(count_labels, bins = 8, density = True)\n",
    "    pdf = counts / (sum(counts))\n",
    "    cdf = np.cumsum(pdf)\n",
    "    plt.plot(bin_edges[1:], cdf)\n",
    "    plt.xlabel('Height of Images', fontsize = 10)\n",
    "    plt.ylabel('CDF', fontsize = 10)\n",
    "    plt.title('CDF Plot of Image Height', fontsize = 12)\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Графік CDF (акумулююча функція) для широт картинок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdf_image_widths(label_len):\n",
    "    \"\"\"\n",
    "    Takes a list of image widths as input and Plots CDF of image widths\n",
    "    \"\"\"\n",
    "    plt.figure(figsize = (10,6))\n",
    "    count_labels = np.array(label_len)\n",
    "    counts, bin_edges = np.histogram(count_labels, bins = 8, density = True)\n",
    "    pdf = counts / (sum(counts))\n",
    "    cdf = np.cumsum(pdf)\n",
    "    plt.plot(bin_edges[1:], cdf)\n",
    "    plt.xlabel('Width of Images', fontsize=10)\n",
    "    plt.ylabel('CDF', fontsize=10)\n",
    "    plt.title('CDF Plot of Image Width', fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cdf_image_heights(train_img_size['Height'].values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цей графік показує, що навчальні картинки більш менш рівномірно розподілені по висоті від 29 до 31 пікселя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cdf_image_widths(train_img_size['Width'].values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цей графік показує, що 85% ширин картинок десь до 170 пікселів, інші 13% до 250 пікселів, і менше 2% це картинки більшої ширини"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Враховуючи результати досліждень розміру картинок можна дійти висновку що найкращим розширенням для моделі мало б бути 32х170 пікселів"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from PIL import Image as pilImg\n",
    "import os \n",
    "import cv2\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import random\n",
    "from keras import backend as K\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Базові константи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Letters present in the Label Text\n",
    "letters = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "#image height\n",
    "img_h = 32\n",
    "#image width\n",
    "img_w = 170\n",
    "#image Channels\n",
    "img_c = 1\n",
    "# classes for softmax with number of letters +1 for blank space in ctc\n",
    "num_classes = len(letters) + 1\n",
    "batch_size = 64\n",
    "# considering max length of ground truths labels to be 15\n",
    "max_length = 15 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функція необхідна для навчання - перетворює слово на масив із чисел по letters HAT returns [17,10,29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_words_labels(word):\n",
    "    \"\"\"\n",
    "    Encodes the Ground Truth Labels to a list of Values like eg. HAT returns [17,10,29]\n",
    "    \"\"\"\n",
    "    label_lst = []\n",
    "    for char in word:\n",
    "        label_lst.append(letters.find(char)) # keeping 0 for blank and for padding labels\n",
    "    return label_lst"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протилежна функція, необхідна для тестування мережі - перетворює масив із значенням літер на слово"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_from_labels(labels):\n",
    "    \"\"\"\n",
    "    converts the list of encoded integer labels to word strings like eg. [17,10,29] returns HAT \n",
    "    \"\"\"\n",
    "    txt = []\n",
    "    for ele in labels:\n",
    "        if ele == len(letters): # last element blank space\n",
    "            txt.append(\" \")\n",
    "        else:\n",
    "            txt.append(letters[ele])\n",
    "    return \"\".join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_loss_function(args):\n",
    "    \"\"\"\n",
    "    CTC loss function takes the values passed from the model returns the CTC loss using Keras Backend ctc_batch_cost function\n",
    "    \"\"\"\n",
    "    y_pred, y_true, input_length, label_length = args \n",
    "    # since the first couple outputs of the RNN tend to be garbage we need to discard them, found this from other CRNN approaches\n",
    "    # I Tried by including these outputs but the results turned out to be very bad and got very low accuracies on prediction \n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(y_true, y_pred, input_length, label_length)   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Generator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зчитує дані із файлів, та адаптує їх по розміру під мережу\n",
    "\n",
    "Перемішує дані та ітерується по них"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.callbacks.Callback):\n",
    "    def __init__(self, img_dirpath, img_w, img_h,\n",
    "                 batch_size, n, output_labels, max_text_len=15):\n",
    "        self.img_h = img_h                    #Image Height\n",
    "        self.img_w = img_w                    #Image Width\n",
    "        self.batch_size = batch_size          #Batch size of Input\n",
    "        self.max_text_len = max_text_len      #Maximum Text length of Labels\n",
    "        self.n = n\n",
    "        self.img_dir = img_dirpath[:self.n]     # images list\n",
    "        self.indexes = list(range(self.n))   #List of indices for each image in img_matrix\n",
    "        self.cur_index = 0                   #Current index which points to image being loaded \n",
    "        self.imgs = np.zeros((self.n, self.img_h, self.img_w))\n",
    "        self.texts =  output_labels[:self.n]                  #List of Ground Truth Label texts\n",
    "\n",
    "   \n",
    "    def build_data(self):\n",
    "        \"\"\"\n",
    "        Build The Image Data\n",
    "        \"\"\"\n",
    "        print(self.n, \" Image Loading start...\")\n",
    "        for i, img_file in enumerate(self.img_dir):\n",
    "            img = cv2.imread(img_file)\n",
    "            img = img[:,:,1]                               #Extracting Single Channel Image\n",
    "            img = cv2.resize(img, (self.img_w, self.img_h))\n",
    "            img = img / 255\n",
    "            self.imgs[i, :, :] = img\n",
    "            if i % 10000 == 0:\n",
    "                print(\"Loaded Images: \", i)\n",
    "           \n",
    "        print(\"Number of Texts matches with Total Number of Images :\", len(self.texts) == self.n)\n",
    "        print(self.n, \" Image Loading finish...\")\n",
    "\n",
    "\n",
    "    def next_data(self): \n",
    "        \"\"\"\n",
    "        Returns image and text data pointed by the current index\n",
    "        \"\"\"\n",
    "        self.cur_index += 1\n",
    "        #If current index becomes more than the number of images, make current index 0 \n",
    "        #and shuffle the indices list for random picking of image and text data\n",
    "        if self.cur_index >= self.n:\n",
    "            self.cur_index = 0\n",
    "            random.shuffle(self.indexes)\n",
    "        return self.imgs[self.indexes[self.cur_index]], self.texts[self.indexes[self.cur_index]]\n",
    "\n",
    "    def next_batch(self):\n",
    "        \"\"\"\n",
    "        Creates a batch of images images and text data equal to the batch_size,\n",
    "        computes the parameters needed for CTC and returns the inputs to the Model\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            X_data = np.ones([self.batch_size, self.img_w, self.img_h, 1])  #Single channel Gray Size Scale images for input\n",
    "            #Initilizing with -1 to aid for padding labels of different lengths\n",
    "            Y_data = np.ones([self.batch_size, self.max_text_len])* -1        #Text labels for input\n",
    "            #input_length for CTC which is the number of time-steps of the RNN output\n",
    "            input_length = np.ones((self.batch_size, 1)) * 40\n",
    "            label_length = np.zeros((self.batch_size, 1))                   #label length for CTC\n",
    "            source_str = []                                                 #List to store Ground Truth Labels\n",
    "            for i in range(self.batch_size):\n",
    "                img, text = self.next_data() #getting the image and text data pointed by current index\n",
    "                img = img.T #taking transpose of image\n",
    "                img = np.expand_dims(img, -1)  #expanding image to have a single channel\n",
    "                X_data[i] = img\n",
    "                label = encode_words_labels(text) # encoding label text to integer list and storing in temp label variable\n",
    "                lbl_len=len(label)\n",
    "                Y_data[i, 0:lbl_len] = label #Storing the label till its length and padding others\n",
    "                label_length[i] = len(label)\n",
    "                source_str.append(text) #storing Ground Truth Labels which will be accessed as reference for calculating metrics\n",
    "            \n",
    "            #Preparing the input for the Model\n",
    "            inputs = {\n",
    "                'img_input': X_data,  \n",
    "                'ground_truth_labels': Y_data,  \n",
    "                'input_length': input_length,  \n",
    "                'label_length': label_length,\n",
    "                'source_str': source_str  # used for visualization only\n",
    "            }\n",
    "            #Preparing output for the Model and intializing to zeros\n",
    "            outputs = {'ctc': np.zeros([self.batch_size])}  \n",
    "            yield (inputs, outputs) # Return the Prepared input and output to the Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPool2D, Dense, MaxPooling2D\n",
    "from keras.layers import Activation, Bidirectional\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import add, concatenate\n",
    "from keras.layers import Reshape\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, GRU\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Image_text_recogniser_model(stage, drop_out_rate = 0.35):\n",
    "    \"\"\"\n",
    "    Builds the model by taking in the stage variable which specifes the stage,\n",
    "    if the stage is training: model takes inputs required for computing ctc_batch_cost function\n",
    "    else : model takes input as images which is used for prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_shape = (1, img_w, img_h)\n",
    "    else:\n",
    "        input_shape = (img_w, img_h, 1)\n",
    "       \n",
    "    model_input = Input(shape = input_shape, name = 'img_input', dtype = 'float32')\n",
    "\n",
    "    # Convolution layer \n",
    "    model = Conv2D(64, (3, 3), padding = 'same', name = 'conv1', kernel_initializer = 'he_normal')(model_input) \n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = MaxPooling2D(pool_size = (2, 2), name = 'max1')(model) \n",
    "\n",
    "    model = Conv2D(128, (3, 3), padding = 'same', name = 'conv2', kernel_initializer = 'he_normal')(model) \n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = MaxPooling2D(pool_size = (2, 2), name = 'max2')(model) \n",
    "\n",
    "    model = Conv2D(256, (3, 3), padding = 'same', name = 'conv3', kernel_initializer = 'he_normal')(model) \n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(256, (3, 3), padding = 'same', name = 'conv4', kernel_initializer = 'he_normal')(model)\n",
    "    model = Dropout(drop_out_rate)(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = MaxPooling2D(pool_size = (1, 2), name = 'max3')(model)  \n",
    "\n",
    "    model = Conv2D(512, (3, 3), padding = 'same', name = 'conv5', kernel_initializer = 'he_normal')(model) \n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Conv2D(512, (3, 3), padding = 'same', name = 'conv6')(model)\n",
    "    model = Dropout(drop_out_rate)(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = MaxPooling2D(pool_size = (1, 2), name = 'max4')(model)\n",
    "\n",
    "    model = Conv2D(512, (2, 2), padding = 'same', kernel_initializer = 'he_normal', name = 'con7')(model)\n",
    "    model = Dropout(0.25)(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)    \n",
    "\n",
    "    # CNN to RNN\n",
    "    model = Reshape(target_shape = ((42, 1024)), name = 'reshape')(model)  \n",
    "    model = Dense(64, activation = 'relu', kernel_initializer = 'he_normal', name = 'dense1')(model)  \n",
    "\n",
    "    # RNN layer\n",
    "    model = Bidirectional(LSTM(256, return_sequences = True, kernel_initializer = 'he_normal'), merge_mode = 'sum')(model)\n",
    "    model = Bidirectional(LSTM(256, return_sequences = True, kernel_initializer = 'he_normal'), merge_mode = 'concat')(model)\n",
    "\n",
    "    # transforms RNN output to character activations:\n",
    "    model = Dense(num_classes, kernel_initializer = 'he_normal',name = 'dense2')(model) \n",
    "    y_pred = Activation('softmax', name = 'softmax')(model)\n",
    "\n",
    "    \n",
    "    labels = Input(name = 'ground_truth_labels', shape = [max_length], dtype = 'float32') \n",
    "    input_length = Input(name = 'input_length', shape = [1], dtype = 'int64') \n",
    "    label_length = Input(name = 'label_length', shape = [1], dtype = 'int64') \n",
    "\n",
    "    #CTC loss function\n",
    "    loss_out = Lambda(ctc_loss_function, output_shape = (1,), name = 'ctc')([y_pred, labels, input_length, label_length]) #(None, 1)\n",
    "\n",
    "    if stage == 'train':\n",
    "        return model_input, y_pred, Model(inputs = [model_input, labels, input_length, label_length], outputs = loss_out)\n",
    "    else:\n",
    "        return Model(inputs = [model_input], outputs = y_pred)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " img_input (InputLayer)         [(None, 170, 32, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv1 (Conv2D)                 (None, 170, 32, 64)  640         ['img_input[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 170, 32, 64)  256        ['conv1[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 170, 32, 64)  0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " max1 (MaxPooling2D)            (None, 85, 16, 64)   0           ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv2 (Conv2D)                 (None, 85, 16, 128)  73856       ['max1[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 85, 16, 128)  512        ['conv2[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 85, 16, 128)  0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " max2 (MaxPooling2D)            (None, 42, 8, 128)   0           ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv3 (Conv2D)                 (None, 42, 8, 256)   295168      ['max2[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 42, 8, 256)  1024        ['conv3[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 42, 8, 256)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv4 (Conv2D)                 (None, 42, 8, 256)   590080      ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 42, 8, 256)   0           ['conv4[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 42, 8, 256)  1024        ['dropout_2[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 42, 8, 256)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " max3 (MaxPooling2D)            (None, 42, 4, 256)   0           ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " conv5 (Conv2D)                 (None, 42, 4, 512)   1180160     ['max3[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 42, 4, 512)  2048        ['conv5[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 42, 4, 512)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv6 (Conv2D)                 (None, 42, 4, 512)   2359808     ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 42, 4, 512)   0           ['conv6[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 42, 4, 512)  2048        ['dropout_3[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 42, 4, 512)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " max4 (MaxPooling2D)            (None, 42, 2, 512)   0           ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " con7 (Conv2D)                  (None, 42, 2, 512)   1049088     ['max4[0][0]']                   \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 42, 2, 512)   0           ['con7[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 42, 2, 512)  2048        ['dropout_4[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 42, 2, 512)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 42, 1024)     0           ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " dense1 (Dense)                 (None, 42, 64)       65600       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " bidirectional_2 (Bidirectional  (None, 42, 256)     657408      ['dense1[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bidirectional_3 (Bidirectional  (None, 42, 512)     1050624     ['bidirectional_2[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dense2 (Dense)                 (None, 42, 37)       18981       ['bidirectional_3[0][0]']        \n",
      "                                                                                                  \n",
      " softmax (Activation)           (None, 42, 37)       0           ['dense2[0][0]']                 \n",
      "                                                                                                  \n",
      " ground_truth_labels (InputLaye  [(None, 15)]        0           []                               \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " input_length (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " label_length (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " ctc (Lambda)                   (None, 1)            0           ['softmax[0][0]',                \n",
      "                                                                  'ground_truth_labels[0][0]',    \n",
      "                                                                  'input_length[0][0]',           \n",
      "                                                                  'label_length[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,350,373\n",
      "Trainable params: 7,345,893\n",
      "Non-trainable params: 4,480\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_input, y_pred, img_text_recog = Image_text_recogniser_model('train')\n",
    "img_text_recog.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Збереження моделі"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_save = Image_text_recogniser_model('save')\n",
    "config = model_to_save.to_json()\n",
    "with open(\"modelBiggest.json\", \"w\") as outfile:\n",
    "    outfile.write(config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Створення callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for visualization\n",
    "# it is a keras backend function used to capture the model ouputs so that it can be used for decoding and calculating metrics\n",
    "test_func = K.function([model_input], [y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_batch(test_func, word_batch):\n",
    "    \"\"\"\n",
    "    Takes the Batch of Predictions and decodes the Predictions by Best Path Decoding and Returns the Output\n",
    "    \"\"\"\n",
    "    out = test_func([word_batch])[0] #returns the predicted output matrix of the model\n",
    "    ret = []\n",
    "    for j in range(out.shape[0]):\n",
    "        out_best = list(np.argmax(out[j, 2:], 1))\n",
    "        out_best = [k for k, g in itertools.groupby(out_best)]\n",
    "        outstr = words_from_labels(out_best)\n",
    "        ret.append(outstr)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracies(actual_labels,predicted_labels,is_train):\n",
    "    \"\"\"\n",
    "    Takes a List of Actual Outputs, predicted Outputs and returns their accuracy and letter accuracy across\n",
    "    all the labels in the list\n",
    "    \"\"\"\n",
    "    accuracy = 0\n",
    "    letter_acc = 0\n",
    "    letter_cnt = 0\n",
    "    count = 0\n",
    "    for i in range(len(actual_labels)):\n",
    "        predicted_output = predicted_labels[i]\n",
    "        actual_output = actual_labels[i]\n",
    "        count += 1\n",
    "        for j in range(min(len(predicted_output), len(actual_output))):\n",
    "            if predicted_output[j] == actual_output[j]:\n",
    "                letter_acc += 1\n",
    "        letter_cnt += max(len(predicted_output),len(actual_output))\n",
    "        if actual_output == predicted_output:\n",
    "            accuracy += 1\n",
    "    final_accuracy = np.round((accuracy/len(actual_labels))*100, 2)\n",
    "    final_letter_acc = np.round((letter_acc/letter_cnt)*100, 2)\n",
    "    return final_accuracy, final_letter_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VizCallback(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    The Custom Callback created for printing the Accuracy and Letter Accuracy Metrics at the End of Each Epoch\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, test_func, text_img_gen,is_train,acc_compute_batches):\n",
    "        self.test_func = test_func\n",
    "        self.text_img_gen = text_img_gen\n",
    "        self.is_train = is_train                #used to indicate whether the callback is called to for Train or Validation Data\n",
    "        self.acc_batches = acc_compute_batches  # Number of Batches for which the metrics are computed typically equal to steps/epoch\n",
    "\n",
    "    def show_accuracy_metrics(self,num_batches):\n",
    "        \"\"\"\n",
    "        Calculates the accuracy and letter accuracy for each batch of inputs, \n",
    "        and prints the avarage accuracy and letter accuracy across all the batches\n",
    "        \"\"\"\n",
    "        accuracy = 0\n",
    "        letter_accuracy = 0\n",
    "        batches_cnt = num_batches\n",
    "        while batches_cnt > 0:\n",
    "            word_batch = next(self.text_img_gen)[0]   #Gets the next batch from the Data generator\n",
    "            decoded_res = decode_batch(self.test_func,word_batch['img_input'])\n",
    "            actual_res = word_batch['source_str']\n",
    "            acc, let_acc = accuracies(actual_res, decoded_res, self.is_train)\n",
    "            accuracy += acc\n",
    "            letter_accuracy += let_acc\n",
    "            batches_cnt -= 1\n",
    "        accuracy = accuracy/num_batches\n",
    "        letter_accuracy = letter_accuracy/num_batches\n",
    "        if self.is_train:\n",
    "            print(\"Train Average Accuracy of \" + str(num_batches) + \" Batches: \", np.round(accuracy, 2), \" %\")\n",
    "            print(\"Train Average Letter Accuracy of \" + str(num_batches) + \" Batches: \", np.round(letter_accuracy, 2), \" %\")\n",
    "        else:\n",
    "            print(\"Validation Average Accuracy of \" + str(num_batches) + \" Batches: \", np.round(accuracy, 2), \" %\")\n",
    "            print(\"Validation Average Letter Accuracy of \" + str(num_batches) + \" Batches: \", np.round(letter_accuracy, 2), \" %\")\n",
    "            \n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.show_accuracy_metrics(self.acc_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "early_stop = EarlyStopping(monitor = 'val_loss', patience=2, restore_best_weights=True)\n",
    "#del  save_weights_only=True,\n",
    "model_chk_pt = ModelCheckpoint('BiggestModel.{epoch:02d}-{val_loss:.2f}.h5', monitor='val_loss', save_best_only=True, verbose=1, mode = 'auto')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зчитуєм дані"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pandas.read_csv('Train_Final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = [str(x) for x in train_data['Labels'].values]\n",
    "train_paths = [str(x) for x in train_data['ImageName'].values]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У датасеті не усі папки заповнені, є серед них пусті де мали б бути картинки. Ці елементи прописані у файлах, а на практиці їх не існує\n",
    "\n",
    "Такі елементи потрібно проігнорувати"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_nan_cnt = 0\n",
    "train_nan_replaced = False\n",
    "for i in range(len(train_labels)):\n",
    "    if train_labels[i] == 'nan':\n",
    "        train_labels[i] = 'NULL'\n",
    "        train_nan_replaced = True\n",
    "        train_nan_cnt += 1\n",
    "train_nan_cnt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = pandas.read_csv('Validation_Final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_labels = [str(x) for x in validation_data['Labels'].values]\n",
    "validation_paths = [str(x) for x in validation_data['ImageName'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_nan_cnt = 0\n",
    "validation_nan_replaced = False\n",
    "for i in range(len(validation_labels)):\n",
    "    if validation_labels[i] == 'nan':\n",
    "        validation_labels[i] = 'NULL'\n",
    "        validation_nan_replaced = True\n",
    "        validation_nan_cnt += 1\n",
    "validation_nan_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gene = DataGenerator(train_paths, img_w, img_h, batch_size, 200000, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000  Image Loading start...\n",
      "Loaded Images:  0\n",
      "Loaded Images:  10000\n",
      "Loaded Images:  20000\n",
      "Loaded Images:  30000\n",
      "Loaded Images:  40000\n",
      "Loaded Images:  50000\n",
      "Loaded Images:  60000\n",
      "Loaded Images:  70000\n",
      "Loaded Images:  80000\n",
      "Loaded Images:  90000\n",
      "Loaded Images:  100000\n",
      "Loaded Images:  110000\n",
      "Loaded Images:  120000\n",
      "Loaded Images:  130000\n",
      "Loaded Images:  140000\n",
      "Loaded Images:  150000\n",
      "Loaded Images:  160000\n",
      "Loaded Images:  170000\n",
      "Loaded Images:  180000\n",
      "Loaded Images:  190000\n",
      "Number of Texts matches with Total Number of Images : True\n",
      "200000  Image Loading finish...\n"
     ]
    }
   ],
   "source": [
    "train_gene.build_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num_batches = int(train_gene.n/batch_size)\n",
    "viz_cb_train = VizCallback(test_func, train_gene.next_batch(), True, train_num_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_gen = DataGenerator(validation_paths, img_w, img_h, batch_size, 12000, validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000  Image Loading start...\n",
      "Loaded Images:  0\n",
      "Loaded Images:  10000\n",
      "Number of Texts matches with Total Number of Images : True\n",
      "12000  Image Loading finish...\n"
     ]
    }
   ],
   "source": [
    "val_gen.build_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_num_batches = int(val_gen.n / batch_size)\n",
    "viz_cb_val = VizCallback(test_func, val_gen.next_batch(), False, val_num_batches)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "adam = optimizers.Adam()\n",
    "#loss ={'ctc': lambda y_true, y_pred: y_pred}\n",
    "img_text_recog.compile(loss = {'ctc': lambda y_true, y_pred: y_pred}, optimizer = adam)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   4/3125 [..............................] - ETA: 2:58:25 - loss: 2.0383"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m img_text_recog\u001b[39m.\u001b[39;49mfit(train_gene\u001b[39m.\u001b[39;49mnext_batch(),\n\u001b[0;32m      2\u001b[0m                     steps_per_epoch \u001b[39m=\u001b[39;49m \u001b[39mint\u001b[39;49m(train_gene\u001b[39m.\u001b[39;49mn \u001b[39m/\u001b[39;49m batch_size),\n\u001b[0;32m      3\u001b[0m                     epochs \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[0;32m      4\u001b[0m                     callbacks\u001b[39m=\u001b[39;49m[viz_cb_train,viz_cb_val,train_gene,val_gen,early_stop,model_chk_pt],\n\u001b[0;32m      5\u001b[0m                     validation_data \u001b[39m=\u001b[39;49m val_gen\u001b[39m.\u001b[39;49mnext_batch(),\n\u001b[0;32m      6\u001b[0m                     validation_steps \u001b[39m=\u001b[39;49m \u001b[39mint\u001b[39;49m(val_gen\u001b[39m.\u001b[39;49mn \u001b[39m/\u001b[39;49m batch_size))\n",
      "File \u001b[1;32mc:\\Users\\jura1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\jura1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1642\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1643\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1644\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1648\u001b[0m ):\n\u001b[0;32m   1649\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1650\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1652\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\jura1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\jura1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\jura1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_no_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\jura1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\jura1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m     args,\n\u001b[0;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1750\u001b[0m     executing_eagerly)\n\u001b[0;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\jura1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\jura1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "img_text_recog.fit(train_gene.next_batch(),\n",
    "                    steps_per_epoch = int(train_gene.n / batch_size),\n",
    "                    epochs = 1,\n",
    "                    callbacks=[viz_cb_train,viz_cb_val,train_gene,val_gen,early_stop,model_chk_pt],\n",
    "                    validation_data = val_gen.next_batch(),\n",
    "                    validation_steps = int(val_gen.n / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_text_recog.save('model2_run_weights.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_text_recog.load_weights('BiggestModel.03-1.66.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125/3125 [==============================] - ETA: 0s - loss: 1.3936Train Average Accuracy of 3125 Batches:  0.0  %\n",
      "Train Average Letter Accuracy of 3125 Batches:  1.66  %\n",
      "Validation Average Accuracy of 187 Batches:  0.0  %\n",
      "Validation Average Letter Accuracy of 187 Batches:  1.68  %\n",
      "\n",
      "Epoch 1: val_loss improved from 1.65879 to 1.43956, saving model to BiggestModel.01-1.44.h5\n",
      "3125/3125 [==============================] - 17472s 6s/step - loss: 1.3936 - val_loss: 1.4396\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b07486b040>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_text_recog.fit(train_gene.next_batch(),\n",
    "                    steps_per_epoch = int(train_gene.n / batch_size),\n",
    "                    epochs = 1,\n",
    "                    callbacks=[viz_cb_train,viz_cb_val,train_gene,val_gen,early_stop,model_chk_pt],\n",
    "                    validation_data = val_gen.next_batch(),\n",
    "                    validation_steps = int(val_gen.n / batch_size))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "678e3ccaa3a58c800d7467d2471996571664ff30189a01c5b79df8b5c0af31ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
